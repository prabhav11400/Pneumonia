{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsKt-G5iRid9",
        "outputId": "2035d858-3a57-48a7-d241-e0c2373cd1d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b1UXViknywK",
        "outputId": "77bb3968-1208-4deb-a0e7-130475109032"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/Pneumonia.zip -d /content/drive/MyDrive/Pneumonia_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd5NpKlKmFcr",
        "outputId": "8d90e718-d4b3-4cc1-f505-9333373e34dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Image data generator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,            # Normalize the pixel values\n",
        "    rotation_range=15,         # Randomly rotate images by 15 degrees\n",
        "    width_shift_range=0.1,     # Randomly shift images horizontally (10%)\n",
        "    height_shift_range=0.1,    # Randomly shift images vertically (10%)\n",
        "    shear_range=0.2,           # Apply random shear transformations\n",
        "    zoom_range=0.2,            # Randomly zoom into images\n",
        "    brightness_range=[0.8, 1.2],  # Adjust brightness\n",
        "    fill_mode='nearest'        # Fill missing pixels with the nearest pixel\n",
        ")\n",
        "\n",
        "# Load data from the directory\n",
        "train_data = datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Pneumonia_data/Pneumonia/chest_xray/train',\n",
        "    target_size=(224, 224),  # Resize to match input size for model\n",
        "    batch_size=8,            # Small batch size for efficient training\n",
        "    class_mode='categorical'  # Two classes: 'normal' and 'pneumonia'\n",
        ")\n",
        "\n",
        "validation_data = datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Pneumonia_data/Pneumonia/chest_xray/val',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=8,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "from tensorflow.keras.applications import EfficientNetB0, DenseNet121\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Concatenate, Flatten\n",
        "\n",
        "# Input layer\n",
        "input_shape = (224, 224, 3)\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "# EfficientNetB0 feature extraction\n",
        "efficient_net = EfficientNetB0(include_top=False, weights='imagenet', input_tensor=inputs)\n",
        "efficient_net_output = GlobalAveragePooling2D()(efficient_net.output)\n",
        "\n",
        "# DenseNet121 feature extraction\n",
        "dense_net = DenseNet121(include_top=False, weights='imagenet', input_tensor=inputs)\n",
        "dense_net_output = GlobalAveragePooling2D()(dense_net.output)\n",
        "\n",
        "# Concatenate features from both networks\n",
        "concatenated_features = Concatenate()([efficient_net_output, dense_net_output])\n",
        "\n",
        "# Add Dropout for regularization\n",
        "concatenated_features = Dropout(0.3)(concatenated_features)\n",
        "\n",
        "# Final classification layer\n",
        "outputs = Dense(2, activation='softmax')(concatenated_features)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLSov-2zm515",
        "outputId": "41fb2ccb-9693-45fb-a133-7d1948be8928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 286ms/step - accuracy: 0.8731 - loss: 0.3173 - val_accuracy: 0.5000 - val_loss: 2.6152\n",
            "Epoch 2/5\n",
            "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 259ms/step - accuracy: 0.9408 - loss: 0.1611 - val_accuracy: 0.8750 - val_loss: 0.3575\n",
            "Epoch 3/5\n",
            "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 252ms/step - accuracy: 0.9588 - loss: 0.1172 - val_accuracy: 0.8125 - val_loss: 0.6075\n",
            "Epoch 4/5\n",
            "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 252ms/step - accuracy: 0.9632 - loss: 0.1041 - val_accuracy: 0.8125 - val_loss: 0.4942\n",
            "Epoch 5/5\n",
            "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 255ms/step - accuracy: 0.9665 - loss: 0.0933 - val_accuracy: 0.6875 - val_loss: 0.5029\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_data, validation_data=validation_data, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTRbRfyJnIz5",
        "outputId": "ae3e5e2e-0540-43dd-92a4-e3497a1d7e88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 624 images belonging to 2 classes.\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - accuracy: 0.9313 - loss: 0.2259\n",
            "Test accuracy: 0.9214743375778198\n"
          ]
        }
      ],
      "source": [
        "# Image data generator for the test set (no augmentation, just rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the test data\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Pneumonia_data/Pneumonia/chest_xray/test',  # Path to the test dataset\n",
        "    target_size=(224, 224),  # Resize to match input size for model\n",
        "    batch_size=8,            # Batch size can be the same as training\n",
        "    class_mode='categorical',  # Two classes: 'normal' and 'pneumonia'\n",
        "    shuffle=False            # Important: don't shuffle for evaluation\n",
        ")\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_data)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQvCqkfzSDM4",
        "outputId": "d54edbe7-3b75-47fa-ddf4-07ac74c98ca2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - accuracy: 0.9313 - loss: 0.2259\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 104ms/step\n",
            "[[216  18]\n",
            " [ 31 359]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.87      0.92      0.90       234\n",
            "   Pneumonia       0.95      0.92      0.94       390\n",
            "\n",
            "    accuracy                           0.92       624\n",
            "   macro avg       0.91      0.92      0.92       624\n",
            "weighted avg       0.92      0.92      0.92       624\n",
            "\n",
            "AUC: 0.9765066841989919\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Evaluate on the test data\n",
        "test_loss, test_acc = model.evaluate(test_data)\n",
        "\n",
        "# Predict on test data to get confusion matrix, precision, recall, etc.\n",
        "y_true = test_data.classes\n",
        "y_pred_probs = model.predict(test_data)\n",
        "y_pred = y_pred_probs.argmax(axis=1)\n",
        "\n",
        "# Confusion Matrix\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# Classification Report (precision, recall, f1-score)\n",
        "print(classification_report(y_true, y_pred, target_names=['Normal', 'Pneumonia']))\n",
        "\n",
        "# AUC score\n",
        "auc = roc_auc_score(y_true, y_pred_probs[:, 1])\n",
        "print(f\"AUC: {auc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90J9v6xSnbqG",
        "outputId": "85aecf89-debc-4b31-fd93-f662d32c6925"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save(\"model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TDtsCzlysAUS"
      },
      "outputs": [],
      "source": [
        "model.save(\"model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8I9cPBjcsBwc"
      },
      "outputs": [],
      "source": [
        "tf.saved_model.save(model, \"saved_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bNX3yy8ZsGPe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 17810,
          "sourceId": 23812,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
